## پروژه طبقه‌بندی سرطان سینه (Breast Cancer Classification)

این پروژه بخشی از تمرین‌های درس یادگیری ماشین است که هدف آن طبقه‌بندی خوش‌خیم (benign) و بدخیم (malignant) بودن تومور سینه با استفاده از ویژگی‌های استخراج‌شده از تصاویر پزشکی است. کل پیاده‌سازی در نوت‌بوک [02_Classification_Breast_Cancer.ipynb](file:///d:/Programming/ML%20Project%20for%20College/machine-learning-portfolio/02-03-classification/02_Classification_Breast_Cancer.ipynb) قرار دارد و خروجی HTML آن در فایل [02_Classification_Breast_Cancer.html](file:///d:/Programming/ML%20Project%20for%20College/machine-learning-portfolio/02-03-classification/02_Classification_Breast_Cancer.html) قابل مشاهده است.

---

## ساختار پوشه پروژه

- `02_Classification_Breast_Cancer.ipynb`  
  نوت‌بوک اصلی شامل تمام مراحل تحلیل، پیش‌پردازش و آموزش مدل‌ها.
- `02_Classification_Breast_Cancer.html`  
  خروجی رندر شده نوت‌بوک برای مشاهده بدون نیاز به اجرای کد.
- `data/data.csv`  
  نسخه ذخیره‌شده داده‌ها (هدف نهایی از دیتاست سرطان سینه اسکیکیت‌لرن).
- پوشه `images/`  
  شامل نمودارهایی که برای گزارش نهایی استخراج شده‌اند:
  - `images/01.png` – نمودار توزیع کلاس‌ها  
  - `images/02.png` – نمودارهای پراکندگی چند ویژگی مهم  
  - `images/03.png` – هیستوگرام ویژگی‌های مهم  
  - `images/04.png` – ماتریس همبستگی ویژگی‌های مهم  
  - `images/05.png` – منحنی‌های یادگیری مدل‌ها بر حسب درصد داده آموزشی  
  - `images/06.png` – ماتریس‌های آشفتگی (Confusion Matrix) برای هر مدل

---

## توصیف دیتاست

- منبع داده: `load_breast_cancer` از کتابخانه `scikit-learn`  
- تعداد نمونه‌ها: 569  
- تعداد ویژگی‌ها: 30 ویژگی عددی از جمله:
  - `mean radius`، `mean texture`، `mean perimeter`، `mean area` و ...  
  - ویژگی‌های خطا (`radius error`، `texture error`، ...)  
  - ویژگی‌های بدترین حالت (`worst radius`، `worst concavity`، ...)
- متغیر هدف (`data/data.csv`):
  - مقدار `0` → تومور بدخیم (`malignant`)  
  - مقدار `1` → تومور خوش‌خیم (`benign`)

در اولین مرحله، داده‌ها به یک `DataFrame` پانداس تبدیل شده و با استفاده از `head()` و `info()` ساختار کلی داده‌ها بررسی شده است.

---

## تحلیل اکتشافی داده‌ها (EDA)

### ۱. بررسی کلی و توزیع کلاس‌ها

- خروجی `df.info()` نشان می‌دهد:
  - 569 ردیف و 31 ستون (30 ویژگی + برچسب هدف)
  - هیچ مقدار گمشده‌ای در هیچ ویژگی وجود ندارد.
- توزیع کلاس‌ها:
  - حدود 63٪ نمونه‌ها `benign`
  - حدود 37٪ نمونه‌ها `malignant`

نمودار توزیع کلاس‌ها با استفاده از `seaborn.countplot` رسم شده است:

![توزیع کلاس‌های هدف](images/01.png)

این نمودار نشان می‌دهد که داده‌ها کمی نامتوازن هستند اما عدم توازن شدید نیست و می‌توان از Accuracy به‌عنوان معیار اصلی استفاده کرد.

### ۲. همبستگی ویژگی‌ها با برچسب هدف

همبستگی پیرسون بین تمام ویژگی‌ها و متغیر هدف محاسبه شده است. ده ویژگی با بیشترین همبستگی مطلق با هدف عبارت‌اند از:

- `worst concave points`  
- `worst perimeter`  
- `mean concave points`  
- `worst radius`  
- `mean perimeter`  
- `worst area`  
- `mean radius`  
- `mean area`  
- `mean concavity`  
- `worst concavity`

این ویژگی‌ها اهمیت زیادی در جداسازی دو کلاس دارند و در ادامه برای ترسیم نمودارها و تفسیر مدل استفاده شده‌اند.

### ۳. نمودارهای پراکندگی ویژگی‌های مهم

برای سه ویژگی مهم:

- `worst concave points`  
- `mean concave points`  
- `worst radius`

یک `pairplot` با رنگ‌بندی بر اساس کلاس هدف رسم شده است:

![نمودار پراکندگی ویژگی‌های مهم](images/02.png)

نتیجه‌گیری از این نمودار:

- نمونه‌های بدخیم و خوش‌خیم در فضای این ویژگی‌ها تا حد زیادی از هم جدا می‌شوند.
- ویژگی‌های مرتبط با concavity و radius در جداسازی کلاس‌ها نقش پررنگی دارند.

### ۴. توزیع ویژگی‌های مهم (هیستوگرام‌ها)

برای همان سه ویژگی مهم، هیستوگرام توزیع مقادیر رسم شده است:

![توزیع ویژگی‌های مهم](images/03.png)

مشاهدات:

- توزیع مقادیر برای کلاس‌های مختلف تفاوت قابل توجهی دارد.
- این تفاوت توزیع دلیل اصلی قدرت مدل‌ها در تشخیص دو کلاس است.

### ۵. ماتریس همبستگی ویژگی‌های مهم

براساس بالاترین مقادیر همبستگی با هدف، 15 ویژگی انتخاب شده و ماتریس همبستگی آن‌ها ترسیم شده است:

![ماتریس همبستگی ویژگی‌های مهم](images/04.png)

نکات مهم:

- بسیاری از ویژگی‌های `mean` و `worst` با هم همبستگی بالایی دارند (رد پای افزونگی ویژگی‌ها).  
- این موضوع نشان می‌دهد که امکان کاهش ابعاد (مثلاً با PCA یا انتخاب ویژگی) در آینده وجود دارد، بدون اینکه دقت مدل به‌شدت افت کند.

---

## مدیریت داده‌های گمشده (Missing Values)

با استفاده از `df.isnull().sum().sum()` تعداد کل مقادیر گمشده بررسی شده است:

- تعداد مقادیر گمشده در کل دیتاست برابر با **۰** است.

در نتیجه نیازی به حذف ردیف‌ها یا اعمال روش‌های تخمین مقادیر گمشده نبوده است.

---

## پیش‌پردازش و تقسیم داده‌ها

### ۱. جداسازی ویژگی‌ها و برچسب هدف

- `X`: همه ستون‌ها به جز `data/data.csv`  
- `y`: ستون `data/data.csv` به‌عنوان برچسب هدف

### ۲. مقیاس‌بندی (Standardization)

از `StandardScaler` برای نرمال‌سازی ویژگی‌ها استفاده شده است:

- داده‌ها ابتدا بر اساس میانگین و انحراف معیار استاندارد شده‌اند.
- این کار برای مدل‌هایی مانند SVM و kNN ضروری است، چون این مدل‌ها به مقیاس ویژگی‌ها حساس‌اند.

### ۳. تقسیم داده‌ها به Train و Test

از `train_test_split` با تنظیمات زیر استفاده شده است:

- `test_size = 0.2` → 20٪ داده برای تست، 80٪ برای آموزش  
- `random_state = 42` → قابل تکرار بودن نتایج  
- `stratify = y` → حفظ نسبت کلاس‌ها در هر دو بخش آموزش و تست

خروجی:

- اندازه داده آموزشی: 455 نمونه  
- اندازه داده تست: 114 نمونه

---

## تعریف تابع ارزیابی بر حسب اندازه داده آموزشی

تابع `evaluate_with_different_sizes` برای هر مدل کارهای زیر را انجام می‌دهد:

- انتخاب 10 درصد تا 100 درصد داده‌های آموزشی (در 10 گام)  
- آموزش مدل روی زیرمجموعه‌های مختلف از داده آموزشی  
- محاسبه Accuracy روی داده تست برای هر زیرمجموعه  
- رسم منحنی تغییر Accuracy بر حسب درصد داده آموزشی  
- در انتها، آموزش مدل روی **کل** داده آموزشی و محاسبه:
  - Accuracy نهایی  
  - `classification_report` شامل precision، recall و f1-score برای هر کلاس

این طراحی باعث شده علاوه بر مقایسه نهایی مدل‌ها، روند یادگیری هر مدل نسبت به حجم داده نیز دیده شود.

---

## مدل‌های استفاده‌شده

چهار مدل کلاسیک یادگیری نظارت‌شده برای طبقه‌بندی دودویی پیاده‌سازی شده است:

1. **Logistic Regression**
   - با `max_iter=10000` برای اطمینان از همگرایی.
   - عملکرد بسیار خوب و پایدار روی دیتاست.

2. **Linear SVM**
   - استفاده از کرنل خطی (`kernel='linear'`).
   - مناسب برای داده‌های نسبتاً قابل جداسازی خطی.

3. **RBF SVM**
   - کرنل غیرخطی RBF با `gamma='scale'`.
   - توانایی مدل‌سازی مرزهای پیچیده‌تر بین کلاس‌ها.

4. **k-Nearest Neighbors (kNN)**
   - انتخاب بهترین `k` با استفاده از `GridSearchCV` و اعتبارسنجی متقاطع (`cv=5`).  
   - بازه جستجو: `k` از 3 تا 19.  
   - بهترین مقدار انتخاب‌شده: **k = 7**.

تمام مدل‌ها روی داده‌های مقیاس‌بندی‌شده آموزش داده شده‌اند.

---

## نتایج کمی مدل‌ها

خلاصه نتایج نهایی روی داده تست (با استفاده از کل داده آموزشی برای آموزش هر مدل):

| مدل                 | Accuracy روی تست |
| -------------------- | ---------------- |
| Logistic Regression  | 0.9825           |
| Linear SVM           | 0.9737           |
| RBF SVM              | 0.9825           |
| kNN (k = 7)          | 0.9649           |

نکات مهم:

- هر چهار مدل عملکرد بسیار خوبی دارند (همگی بالاتر از 96٪).  
- Logistic Regression و RBF SVM بهترین عملکرد را با Accuracy حدود 98.25٪ روی داده تست نشان می‌دهند.  
- مقادیر precision، recall و f1-score برای هر دو کلاس نیز بسیار بالا (نزدیک 1) گزارش شده‌اند، که نشان‌دهنده تعادل خوب بین دو کلاس است.

---

## منحنی‌های یادگیری بر اساس درصد داده آموزشی

خروجی تابع ارزیابی برای هر مدل در یک شکل واحد رسم شده است:

![منحنی‌های یادگیری مدل‌ها](images/05.png)

برداشت از منحنی‌ها:

- با افزایش درصد داده آموزشی، Accuracy روی تست برای تمام مدل‌ها به محدوده‌ای نزدیک 0.97–0.99 همگرا می‌شود.  
- مدل‌ها نسبت به اندازه داده آموزشی رفتار منطقی و پایدار دارند و نشانه‌ای از overfitting شدید دیده نمی‌شود.  
- اختلاف عملکرد بین مدل‌ها نسبتاً کم است، اما در اکثر نقاط Logistic Regression و RBF SVM کمی بهتر عمل می‌کنند.

---

## ماتریس‌های آشفتگی (Confusion Matrix)

برای مقایسه دقیق‌تر، برای هر مدل یک ماتریس آشفتگی روی داده تست رسم شده است:

![ماتریس‌های آشفتگی مدل‌ها](images/06.png)

نتایج کلی:

- تعداد خطاها در هر چهار مدل بسیار کم است.  
- مدل‌ها در تشخیص هر دو کلاس موفق عمل کرده‌اند، اما خطاهای اندکی در تشخیص تومورهای بدخیم و خوش‌خیم مشاهده می‌شود.  
- این تحلیل تأیید می‌کند که مدل‌ها نه‌تنها از نظر Accuracy، بلکه از نظر توازن بین precision و recall نیز مناسب‌اند.

---

## نحوه اجرای کد

برای اجرای نوت‌بوک روی سیستم خود، مراحل زیر را می‌توانید انجام دهید:

1. ایجاد محیط پایتون (مثلاً با Anaconda یا venv).  
2. نصب کتابخانه‌های مورد نیاز (نسخه‌های مشابه محیط فعلی):
   - `pandas`  
   - `numpy`  
   - `matplotlib`  
   - `seaborn`  
   - `scikit-learn`  
   - `arabic_reshaper`  
   - `python-bidi`  
3. باز کردن فایل نوت‌بوک در Jupyter Notebook یا JupyterLab:  
   - `02_Classification_Breast_Cancer.ipynb`  
4. اجرای سلول‌ها از ابتدا تا انتها برای بازتولید تمام نتایج و نمودارها.

