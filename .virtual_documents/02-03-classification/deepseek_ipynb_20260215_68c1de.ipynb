


# 1. وارد کردن کتابخانه‌ها
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# کتابخانه‌های مربوط به متن فارسی
import arabic_reshaper
from bidi.algorithm import get_display

# تنظیم فونت برای پشتیبانی از فارسی در نمودارها
import matplotlib.font_manager as fm
font_path = None
for font in fm.findSystemFonts():
    if 'Arial' in font or 'DejaVu' in font or 'Noto' in font:
        font_path = font
        break
if font_path:
    prop = fm.FontProperties(fname=font_path)
    plt.rcParams['font.family'] = prop.get_name()
else:
    print("هشدار: فونت مناسب برای فارسی یافت نشد. ممکن است متون فارسی به درستی نمایش داده نشوند.")

# تابع کمکی برای آماده‌سازی متن فارسی
def persian_text(text):
    reshaped = arabic_reshaper.reshape(text)
    return get_display(reshaped)

# کتابخانه‌های مدل‌سازی
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.svm import LinearSVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# تنظیمات نمایش
pd.set_option('display.max_columns', None)
sns.set_style('whitegrid')





# بارگذاری فایل CSV
file_path = "data/data.csv"
df = pd.read_csv(file_path)
print("ابعاد داده:", df.shape)
df.head()





# اطلاعات ستون‌ها
df.info()


# آمار توصیفی برای متغیرهای عددی
df.describe()


# بررسی مقادیر گم‌شده
missing = df.isnull().sum()
missing[missing > 0]





# بررسی نوع داده‌ها و تعداد مقادیر یکتا در ستون‌های categorical
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    print(f"{col}: {df[col].nunique()} مقدار یکتا - نمونه: {df[col].unique()[:5]}")





# تعیین متغیر هدف (با فرض G3)
target_col = 'G3'  # در صورت نیاز تغییر دهید
if target_col not in df.columns:
    print("ستون هدف یافت نشد. لطفاً نام صحیح را در سلول بعدی تنظیم کنید.")
else:
    # توزیع متغیر هدف
    plt.figure(figsize=(8,5))
    sns.histplot(df[target_col], bins=20, kde=True)
    plt.title(persian_text('توزیع متغیر هدف'))
    plt.xlabel(persian_text('مقدار'))
    plt.ylabel(persian_text('تعداد'))
    plt.show()


# اگر داده شامل ستون‌های عددی مشابه G1, G2 باشد، رابطه آنها را با هدف بررسی می‌کنیم
# این بخش قابل تنظیم بر اساس داده شماست
if target_col in df.columns:
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # حذف target از لیست برای جلوگیری از رسم خودش
    feature_cols = [col for col in numeric_cols if col != target_col]
    # اگر بیش از یک ویژگی عددی وجود دارد، دو مورد اول را برای نمایش انتخاب می‌کنیم
    if len(feature_cols) >= 2:
        fig, axes = plt.subplots(1,2, figsize=(12,5))
        sns.scatterplot(data=df, x=feature_cols[0], y=target_col, ax=axes[0])
        axes[0].set_title(persian_text(f'رابطه {feature_cols[0]} و هدف'))
        sns.scatterplot(data=df, x=feature_cols[1], y=target_col, ax=axes[1])
        axes[1].set_title(persian_text(f'رابطه {feature_cols[1]} و هدف'))
        plt.tight_layout()
        plt.show()


# بررسی تأثیر یک ویژگی categorical (در صورت وجود) روی هدف
if len(categorical_cols) > 0 and target_col in df.columns:
    # اولین ستون categorical را انتخاب می‌کنیم
    cat_col = categorical_cols[0]
    plt.figure(figsize=(10,6))
    sns.boxplot(data=df, x=cat_col, y=target_col)
    plt.title(persian_text(f'توزیع هدف بر اساس {cat_col}'))
    plt.xlabel(persian_text(cat_col))
    plt.ylabel(persian_text('هدف'))
    plt.xticks(rotation=45)
    plt.show()


# ماتریس همبستگی برای متغیرهای عددی
numeric_cols = df.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 1:
    plt.figure(figsize=(12,8))
    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')
    plt.title(persian_text('ماتریس همبستگی ویژگی‌های عددی'))
    plt.show()





# اگر target_col وجود ندارد، از کاربر می‌خواهیم تعریف کند
if target_col not in df.columns:
    # در اینجا می‌توان یک ورودی گرفت یا از ستون آخر استفاده کرد
    target_col = df.columns[-1]  # فرض می‌کنیم هدف آخرین ستون است
    print(f"ستون هدف به صورت خودکار '{target_col}' انتخاب شد.")

X = df.drop(target_col, axis=1)
y = df[target_col]

# شناسایی ستون‌های عددی و category
num_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()

print("ویژگی‌های عددی:", num_features)
print("ویژگی‌های category:", cat_features)


# ایجاد پیش‌پردازنده
transformers = []
if num_features:
    transformers.append(('num', StandardScaler(), num_features))
if cat_features:
    transformers.append(('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features))

preprocessor = ColumnTransformer(transformers=transformers)

# تقسیم داده‌ها به آموزش و آزمون
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# اعمال پیش‌پردازش
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print("اندازه مجموعه آموزش:", X_train_processed.shape)
print("اندازه مجموعه آزمون:", X_test_processed.shape)





# تعریف مدل‌ها
models = {
    'رگرسیون خطی': LinearRegression(),
    'SVM خطی': LinearSVR(max_iter=10000, random_state=42),
    'kNN': KNeighborsRegressor(n_neighbors=5)
}

# آموزش و ذخیره نتایج
results = {}
for name, model in models.items():
    model.fit(X_train_processed, y_train)
    y_pred = model.predict(X_test_processed)
    
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    results[name] = {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'y_pred': y_pred
    }
    
    print(f"\n{name}:")
    print(f"  MSE: {mse:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MAE: {mae:.4f}")
    print(f"  R²: {r2:.4f}")





# ایجاد دیتافریم نتایج
results_df = pd.DataFrame({
    name: {k: v for k, v in res.items() if k != 'y_pred'} 
    for name, res in results.items()
}).T

results_df


# نمودار مقایسه معیارها
fig, axes = plt.subplots(2,2, figsize=(14,10))
metrics = ['MSE', 'RMSE', 'MAE', 'R2']
for i, metric in enumerate(metrics):
    ax = axes[i//2, i%2]
    results_df[metric].plot(kind='bar', ax=ax, color=['skyblue', 'lightcoral', 'lightgreen'])
    ax.set_title(persian_text(f'مقایسه {metric}'))
    ax.set_ylabel(persian_text(metric))
    ax.set_xlabel(persian_text('مدل'))
    ax.tick_params(axis='x', rotation=0)
    for p in ax.patches:
        ax.annotate(f'{p.get_height():.3f}', (p.get_x() + p.get_width()/2., p.get_height()),
                    ha='center', va='bottom')
plt.tight_layout()
plt.show()


# نمودار مقادیر واقعی در مقابل پیش‌بینی برای هر مدل
fig, axes = plt.subplots(1,3, figsize=(18,5))
for ax, (name, res) in zip(axes, results.items()):
    ax.scatter(y_test, res['y_pred'], alpha=0.6)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    ax.set_xlabel(persian_text('مقادیر واقعی'))
    ax.set_ylabel(persian_text('مقادیر پیش‌بینی'))
    ax.set_title(persian_text(f'مدل {name}'))
plt.tight_layout()
plt.show()


# نمودار residuals برای بررسی خطاها
fig, axes = plt.subplots(1,3, figsize=(18,5))
for ax, (name, res) in zip(axes, results.items()):
    residuals = y_test - res['y_pred']
    ax.scatter(res['y_pred'], residuals, alpha=0.6)
    ax.axhline(y=0, color='r', linestyle='--')
    ax.set_xlabel(persian_text('مقادیر پیش‌بینی'))
    ax.set_ylabel(persian_text('باقیمانده'))
    ax.set_title(persian_text(f'نمودار باقیمانده - {name}'))
plt.tight_layout()
plt.show()



